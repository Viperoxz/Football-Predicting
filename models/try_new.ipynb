{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from GRUconfig import GRUconfig\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import GRU, CrossEntropyLoss\n",
    "from torch import optim\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "from GRUconfig import GRUconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import json\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/team_map.json', 'r') as file:\n",
    "    team_map_dict = json.load(file)\n",
    "result_cols = ['result_A', 'result_D', 'result_H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/preprocessed/layer1/matches_stats_data_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[col for col in df if col not in result_cols]+[col for col in result_cols if col in df]]\n",
    "df['season'] = df['season'].apply(lambda x:  int(x[2:4]) - 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['result_H'] = df['result_H'].apply(lambda x: 1 if x else 0)\n",
    "df['result_A'] = df['result_A'].apply(lambda x: 1 if x else 0)\n",
    "df['result_D'] = df['result_D'].apply(lambda x: 1 if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hometeam', 'awayteam', 'date', 'season', 'round', 'gf', 'ga', 'h_xg',\n",
       "       'h_xga', 'h_standard sot', 'h_kp', 'h_xa', 'h_poss_x',\n",
       "       'h_touches att pen', 'h_carries prgdist', 'h_progressive passing dist',\n",
       "       'h_tackles tklw', 'h_challenges tkl%', 'h_saves', 'a_xg', 'a_xga',\n",
       "       'a_standard sot', 'a_kp', 'a_xa', 'a_poss_x', 'a_touches att pen',\n",
       "       'a_carries prgdist', 'a_progressive passing dist', 'a_tackles tklw',\n",
       "       'a_challenges tkl%', 'a_saves', 'b365h', 'b365d', 'b365a',\n",
       "       'h_strength_overall_home', 'h_overall_rating', 'h_attack_rating',\n",
       "       'h_midfield_rating', 'h_defence_rating', 'h_avg_age',\n",
       "       'a_strength_overall_away', 'a_overall_rating', 'a_attack_rating',\n",
       "       'a_midfield_rating', 'a_defence_rating', 'a_avg_age', 'soh', 'soa',\n",
       "       'result_A', 'result_D', 'result_H'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_columns = ['result_H',\n",
    "                'gf','ga', \n",
    "                'h_xg',\n",
    "                'h_xga', 'h_standard sot', 'h_kp', 'h_xa', 'h_poss_x',\n",
    "                'h_touches att pen', 'h_carries prgdist', 'h_progressive passing dist',\n",
    "                'h_tackles tklw', 'h_challenges tkl%', 'h_saves',\n",
    "                'h_strength_overall_home', 'h_overall_rating', 'h_attack_rating',\n",
    "                'h_midfield_rating', 'h_defence_rating', 'h_avg_age','soh']\n",
    "away_columns = ['result_A',\n",
    "                'ga','gf',\n",
    "                'a_xg', \n",
    "                'a_xga','a_standard sot', 'a_kp', 'a_xa', 'a_poss_x', \n",
    "                'a_touches att pen','a_carries prgdist', 'a_progressive passing dist', \n",
    "                'a_tackles tklw','a_challenges tkl%', 'a_saves',\n",
    "                'a_strength_overall_away', 'a_overall_rating', 'a_attack_rating',\n",
    "                'a_midfield_rating', 'a_defence_rating', 'a_avg_age', 'soa']\n",
    "bet_columns = ['b365h', 'b365d', 'b365a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hometeam</th>\n",
       "      <th>awayteam</th>\n",
       "      <th>season</th>\n",
       "      <th>round</th>\n",
       "      <th>gf</th>\n",
       "      <th>ga</th>\n",
       "      <th>h_xg</th>\n",
       "      <th>h_xga</th>\n",
       "      <th>h_standard sot</th>\n",
       "      <th>h_kp</th>\n",
       "      <th>...</th>\n",
       "      <th>a_overall_rating</th>\n",
       "      <th>a_attack_rating</th>\n",
       "      <th>a_midfield_rating</th>\n",
       "      <th>a_defence_rating</th>\n",
       "      <th>a_avg_age</th>\n",
       "      <th>soh</th>\n",
       "      <th>soa</th>\n",
       "      <th>result_A</th>\n",
       "      <th>result_D</th>\n",
       "      <th>result_H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRY</td>\n",
       "      <td>SOU</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.562586</td>\n",
       "      <td>0.353518</td>\n",
       "      <td>0.349016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUL</td>\n",
       "      <td>ARS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.375516</td>\n",
       "      <td>0.353518</td>\n",
       "      <td>0.491616</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIV</td>\n",
       "      <td>LEE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.425034</td>\n",
       "      <td>0.514222</td>\n",
       "      <td>0.415563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WHU</td>\n",
       "      <td>NEW</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.675378</td>\n",
       "      <td>0.494134</td>\n",
       "      <td>0.320495</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOT</td>\n",
       "      <td>EVE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.662999</td>\n",
       "      <td>0.453958</td>\n",
       "      <td>0.377536</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>SOU</td>\n",
       "      <td>EVE</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.270891</td>\n",
       "      <td>0.277075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>WOL</td>\n",
       "      <td>CRY</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.449794</td>\n",
       "      <td>0.817935</td>\n",
       "      <td>0.571101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>MUN</td>\n",
       "      <td>CHE</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.088033</td>\n",
       "      <td>0.515520</td>\n",
       "      <td>0.722152</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>TOT</td>\n",
       "      <td>AVL</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.562586</td>\n",
       "      <td>0.559673</td>\n",
       "      <td>0.480735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>FUL</td>\n",
       "      <td>BRE</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.550206</td>\n",
       "      <td>0.276302</td>\n",
       "      <td>0.194562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1620 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hometeam awayteam  season  round   gf   ga      h_xg     h_xga  \\\n",
       "0         CRY      SOU       1      1  1.0  0.0  0.157143  0.128571   \n",
       "1         FUL      ARS       1      1  0.0  3.0  0.014286  0.271429   \n",
       "2         LIV      LEE       1      1  4.0  3.0  0.385714  0.042857   \n",
       "3         WHU      NEW       1      1  0.0  2.0  0.142857  0.228571   \n",
       "4         TOT      EVE       1      1  0.0  1.0  0.157143  0.171429   \n",
       "...       ...      ...     ...    ...  ...  ...       ...       ...   \n",
       "1615      SOU      EVE       5     10  1.0  0.0  0.100000  0.228571   \n",
       "1616      WOL      CRY       5     10  2.0  2.0  0.214286  0.342857   \n",
       "1617      MUN      CHE       5     10  1.0  1.0  0.285714  0.157143   \n",
       "1618      TOT      AVL       5     10  4.0  1.0  0.342857  0.257143   \n",
       "1619      FUL      BRE       5     10  2.0  1.0  0.185714  0.085714   \n",
       "\n",
       "      h_standard sot      h_kp  ...  a_overall_rating  a_attack_rating  \\\n",
       "0             0.1875  0.166667  ...          0.250000         0.333333   \n",
       "1             0.1250  0.100000  ...          0.583333         0.666667   \n",
       "2             0.2500  0.466667  ...          0.250000         0.388889   \n",
       "3             0.1875  0.366667  ...          0.250000         0.333333   \n",
       "4             0.3125  0.300000  ...          0.500000         0.555556   \n",
       "...              ...       ...  ...               ...              ...   \n",
       "1615          0.1250  0.300000  ...          0.250000         0.277778   \n",
       "1616          0.3750  0.300000  ...          0.416667         0.388889   \n",
       "1617          0.1875  0.233333  ...          0.666667         0.555556   \n",
       "1618          0.3750  0.333333  ...          0.583333         0.777778   \n",
       "1619          0.7500  0.633333  ...          0.250000         0.444444   \n",
       "\n",
       "      a_midfield_rating  a_defence_rating  a_avg_age       soh       soa  \\\n",
       "0                0.3750          0.333333   0.562586  0.353518  0.349016   \n",
       "1                0.5000          0.533333   0.375516  0.353518  0.491616   \n",
       "2                0.3125          0.266667   0.425034  0.514222  0.415563   \n",
       "3                0.2500          0.200000   0.675378  0.494134  0.320495   \n",
       "4                0.5000          0.600000   0.662999  0.453958  0.377536   \n",
       "...                 ...               ...        ...       ...       ...   \n",
       "1615             0.3125          0.333333   1.000000  0.270891  0.277075   \n",
       "1616             0.4375          0.400000   0.449794  0.817935  0.571101   \n",
       "1617             0.6250          0.533333   0.088033  0.515520  0.722152   \n",
       "1618             0.5625          0.600000   0.562586  0.559673  0.480735   \n",
       "1619             0.3125          0.333333   0.550206  0.276302  0.194562   \n",
       "\n",
       "      result_A  result_D  result_H  \n",
       "0            0         0         1  \n",
       "1            1         0         0  \n",
       "2            0         0         1  \n",
       "3            1         0         0  \n",
       "4            1         0         0  \n",
       "...        ...       ...       ...  \n",
       "1615         0         0         1  \n",
       "1616         0         1         0  \n",
       "1617         0         1         0  \n",
       "1618         0         0         1  \n",
       "1619         0         0         1  \n",
       "\n",
       "[1620 rows x 50 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns='date')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(ssdf: pd.DataFrame, pre_match: int = 5) -> dict:\n",
    "    teams_data = {}\n",
    "    team_idx = sorted(df['hometeam'].unique())\n",
    "    final = {}\n",
    "    for idx in team_idx:\n",
    "        teams_data[idx] = []\n",
    "        final[idx] = {}\n",
    "    for idx, match in ssdf.iterrows():\n",
    "        hometeam = match['hometeam']\n",
    "        awayteam = match['awayteam']\n",
    "        \n",
    "        tmp_h_data = match[['hometeam', 'awayteam']+home_columns+bet_columns]\n",
    "        tmp_h_data['home'] = 1\n",
    "        tmp_h_data['opponent'] = awayteam\n",
    "        teams_data[hometeam].append(tmp_h_data.values)\n",
    "        \n",
    "        tmp_a_data = match[['hometeam', 'awayteam']+away_columns+bet_columns]\n",
    "        tmp_a_data['home'] = 0\n",
    "        tmp_a_data['opponent'] = hometeam\n",
    "        teams_data[awayteam].append(tmp_a_data.values)\n",
    "    \n",
    "    for team,matches in teams_data.items():\n",
    "        for idx in range(len(matches)-pre_match):\n",
    "            pre_match_data = matches[idx:idx+pre_match]\n",
    "            pre_match_data_key = pre_match_data[-1][0] + pre_match_data[-1][1]\n",
    "            pre_match_data = np.vstack(pre_match_data)\n",
    "            final[team][pre_match_data_key] = [pre_match_data[:, 2:-1], pre_match_data[-1][-1]]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_structure_\\n    [This team win: 1/0][goal score][goal scored][rate-bet x3][home] = 26\\n    -------------------- TEAM 1__________________------------------- = 21 -> 42 +[this team home| other team home][rate-bet x3] = 47\\n'"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"_structure_\n",
    "    [This team win: 1/0][goal score][goal scored][rate-bet x3][home] = 26\n",
    "    -------------------- TEAM 1__________________------------------- = 21 -> 42 +[this team home| other team home][rate-bet x3] = 47\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_y(final_dict: dict, seq: bool = False):\n",
    "    checked_match = []\n",
    "    X = np.empty((0,5,42)) if seq else np.empty((0,47))\n",
    "    y = []\n",
    "    data_dict = {}\n",
    "    for _, match_dict in final_dict.items():\n",
    "        for match_key, match_data in match_dict.items():\n",
    "            match_dict = {}\n",
    "            if match_key in checked_match:\n",
    "                continue\n",
    "            checked_match.append(match_key)\n",
    "            team1_data = match_data[0]\n",
    "            try:\n",
    "                team2_data = final_dict[match_data[1]][match_key][0]\n",
    "            except KeyError:\n",
    "\n",
    "                continue\n",
    "            \n",
    "            team1_home = (team1_data[-1][-1] == 1)\n",
    "            h,d,a = team1_data[-1][-4:-1].tolist()\n",
    "            if team1_home:\n",
    "                bet_rate = np.array([1.,0.,h,d,a])\n",
    "            else:\n",
    "                bet_rate = np.array([0.,1.,a,d,h])\n",
    "            weights = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "            if not seq:\n",
    "                team1_prematch = np.dot(weights, team1_data[:-1,1:-4]).reshape(-1)\n",
    "                team2_prematch = np.dot(weights, team2_data[:-1,1:-4]).reshape(-1)\n",
    "                prematch = np.concatenate((team1_prematch, team2_prematch))\n",
    "                prematch = np.concatenate((prematch, bet_rate))\n",
    "            else:\n",
    "                team1_prematch =  team1_data[:-1,1:-4]\n",
    "                team2_prematch = team2_data[:-1,1:-4]\n",
    "                place_holder = np.zeros((1,42))\n",
    "                place_holder[:,:5] = bet_rate\n",
    "                prematch = np.concatenate((team1_prematch, team2_prematch), axis=1)\n",
    "                prematch = np.concatenate((prematch, place_holder), axis=0).reshape(1,5,42)\n",
    "            \n",
    "            this_match_res = 0 if team1_data[-1][0] == 1 else 2 if team2_data[-1][0] == 1 else 0\n",
    "            X = np.vstack((X, prematch))\n",
    "            y.append(this_match_res)\n",
    "            \n",
    "            match_dict['x'] = prematch\n",
    "            match_dict['y'] = this_match_res\n",
    "            data_dict[match_key] = match_dict\n",
    "    y = np.asarray(y)\n",
    "    return data_dict, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_data(ss: int, prematch:int = 5, seq: bool = False):\n",
    "    global df\n",
    "    tmpss=ss-19\n",
    "    sscheck = df[df['season']==tmpss]\n",
    "    finalss = prepare_data(sscheck, prematch)\n",
    "    _, X, y = create_X_y(finalss, seq)\n",
    "    print(X.shape, y.shape)\n",
    "    if seq:\n",
    "        np.save(f'inputs{ss}_{ss+1}_seq.npy',X)\n",
    "        np.save(f'outputs{ss}_{ss+1}_seq.npy',y)\n",
    "    else:\n",
    "        np.save(f'inputs{ss}_{ss+1}.npy',X)\n",
    "        np.save(f'outputs{ss}_{ss+1}.npy',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328, 47) (328,)\n",
      "(330, 47) (330,)\n",
      "(330, 47) (330,)\n"
     ]
    }
   ],
   "source": [
    "handle_data(20)\n",
    "handle_data(21)\n",
    "handle_data(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_20_1 = np.load('inputs20_21.npy', allow_pickle=True)\n",
    "y_20_1 = np.load('outputs20_21.npy', allow_pickle=True)\n",
    "input_21_1 = np.load('inputs21_22.npy', allow_pickle=True)\n",
    "y_21_1 = np.load('outputs21_22.npy', allow_pickle=True)\n",
    "input_22_1_1 = np.load('inputs22_23.npy', allow_pickle=True)\n",
    "y_22_1_1 = np.load('outputs22_23.npy', allow_pickle=True)\n",
    "\n",
    "INPUTS = np.vstack((input_20_1,input_21_1))\n",
    "INPUTS = np.vstack((INPUTS, input_22_1_1))\n",
    "LABELS = np.concatenate((y_20_1,y_21_1))\n",
    "LABELS = np.concatenate((LABELS, y_22_1_1))\n",
    "train_X, test_X, train_y, test_y = train_test_split(INPUTS, LABELS, test_size = 0.3, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.734006734006734"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_ovo = SVC(decision_function_shape='ovo')\n",
    "svc_ovo.fit(train_X, train_y)\n",
    "y_predict = svc_ovo.predict(test_X)\n",
    "accuracy_score(y_predict, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.734006734006734"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(criterion='entropy')\n",
    "rf_clf.fit(train_X, train_y)\n",
    "y_predict = rf_clf.predict(test_X)\n",
    "accuracy_score(y_predict, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7239057239057239"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xGboost_clf = GradientBoostingClassifier()\n",
    "xGboost_clf.fit(train_X, train_y)\n",
    "y_predict = xGboost_clf.predict(test_X)\n",
    "accuracy_score(y_predict, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(329, 47) (329,)\n"
     ]
    }
   ],
   "source": [
    "handle_data(23)\n",
    "inputs = np.load('inputs23_24.npy', allow_pickle=True)\n",
    "outputs = np.load('outputs23_24.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = svc_ovo.predict(inputs)\n",
    "accuracy_score(y_predict, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('svc_ovo.pkl','wb') as f:\n",
    "#     pickle.dump(svc_ovo,f)\n",
    "\n",
    "# # # load\n",
    "# # with open('svc_model.pkl', 'rb') as f:\n",
    "# #     clf2 = pickle.load(f)\n",
    "\n",
    "# with open('rf.pkl','wb') as f:\n",
    "#     pickle.dump(rf_clf, f)\n",
    "\n",
    "# with open('xGboost.pkl','wb') as f:\n",
    "#     pickle.dump(xGboost_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328, 5, 42) (328,)\n",
      "(330, 5, 42) (330,)\n",
      "(330, 5, 42) (330,)\n"
     ]
    }
   ],
   "source": [
    "handle_data(20, seq=True)\n",
    "handle_data(21, seq=True)\n",
    "handle_data(22, seq=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_model(nn.Module):\n",
    "    def __init__(self, config: GRUconfig):\n",
    "        super(GRU_model, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(5, config.input_size),\n",
    "            GRU(input_size=config.input_size, \n",
    "                hidden_size=config.hidden_size, \n",
    "                num_layers=config.num_layer, \n",
    "                batch_first=True, \n",
    "                dropout=config.drop_out_rate),\n",
    "            nn.Linear(config.hidden_size, 3)  # Output layer: 3 classes\n",
    "        ])\n",
    "    def forward(self, X, Y: None):\n",
    "        bet_vectors = X[:,-1,:5]\n",
    "        X = X[:,:-1]\n",
    "        bet_vectors = self.layers[0](bet_vectors).view(-1,1,42)\n",
    "        X = torch.concat([X, bet_vectors], dim=1)\n",
    "        _, hidden = self.layers[1](X)  # GRU Layer\n",
    "        \n",
    "        # Use the last hidden state from the GRU\n",
    "        last_hidden = hidden[-1]  # Take the last layer's hidden state\n",
    "        \n",
    "        # Pass through the Fully Connected Layer\n",
    "        out_logits = self.layers[2](last_hidden)  # Linear Layer\n",
    "        loss = 0\n",
    "        if Y is not None:\n",
    "            logits = out_logits.contiguous()\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            logits = logits.view(-1, 3)\n",
    "            targets = Y.view(-1)\n",
    "            loss = loss_fct(logits, targets)\n",
    "        return out_logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_20_seq = np.load('inputs20_21_seq.npy', allow_pickle=True)\n",
    "y_20_seq = np.load('outputs20_21_seq.npy', allow_pickle=True)\n",
    "input_21_seq = np.load('inputs21_22_seq.npy', allow_pickle=True)\n",
    "y_21_seq = np.load('outputs21_22_seq.npy', allow_pickle=True)\n",
    "input_22_seq = np.load('inputs22_23_seq.npy', allow_pickle=True)\n",
    "y_22_seq = np.load('outputs22_23_seq.npy', allow_pickle=True)\n",
    "\n",
    "INPUTS = np.vstack((input_20_seq,input_21_seq))\n",
    "INPUTS = np.vstack((INPUTS, input_21_seq))\n",
    "LABELS = np.concatenate((y_20_seq,y_21_seq))\n",
    "LABELS = np.concatenate((LABELS, y_22_seq))\n",
    "train_X, test_X, train_y, test_y = train_test_split(INPUTS, LABELS, test_size = 0.3, shuffle = True)\n",
    "\n",
    "train_X = train_X.astype(np.float32)\n",
    "test_X  = test_X.astype(np.float32)\n",
    "train_y = train_y\n",
    "test_y = test_y\n",
    "\n",
    "train_X = torch.from_numpy(train_X).to(device=device)\n",
    "test_X = torch.from_numpy(test_X).to(device=device)\n",
    "train_y = torch.from_numpy(train_y).to(dtype=torch.long, device=device)\n",
    "test_y = torch.from_numpy(test_y).to(dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, iter:0,loss_train: 1.1039, loss_test: 1.1035, accuracy: 0.07744107395410538\n",
      "epoch:0, iter:10,loss_train: 0.7003, loss_test: 0.6147, accuracy: 0.6936026811599731\n",
      "epoch:0, iter:20,loss_train: 0.6805, loss_test: 0.6802, accuracy: 0.616161584854126\n",
      "epoch:1, iter:0,loss_train: 0.7228, loss_test: 0.7171, accuracy: 0.32996633648872375\n",
      "epoch:1, iter:10,loss_train: 0.6261, loss_test: 0.6094, accuracy: 0.6969696879386902\n",
      "epoch:1, iter:20,loss_train: 0.7175, loss_test: 0.5937, accuracy: 0.7070707082748413\n",
      "epoch:2, iter:0,loss_train: 0.5508, loss_test: 0.6087, accuracy: 0.6868686676025391\n",
      "epoch:2, iter:10,loss_train: 0.6209, loss_test: 0.5862, accuracy: 0.7003366947174072\n",
      "epoch:2, iter:20,loss_train: 0.7070, loss_test: 0.5861, accuracy: 0.6902356743812561\n",
      "epoch:3, iter:0,loss_train: 0.5352, loss_test: 0.5891, accuracy: 0.6936026811599731\n",
      "epoch:3, iter:10,loss_train: 0.6150, loss_test: 0.5774, accuracy: 0.6936026811599731\n",
      "epoch:3, iter:20,loss_train: 0.6714, loss_test: 0.5852, accuracy: 0.6969696879386902\n",
      "epoch:4, iter:0,loss_train: 0.5320, loss_test: 0.5901, accuracy: 0.7003366947174072\n",
      "epoch:4, iter:10,loss_train: 0.6089, loss_test: 0.5710, accuracy: 0.6969696879386902\n",
      "epoch:4, iter:20,loss_train: 0.6681, loss_test: 0.5763, accuracy: 0.6969696879386902\n",
      "epoch:5, iter:0,loss_train: 0.5318, loss_test: 0.5832, accuracy: 0.6969696879386902\n",
      "epoch:5, iter:10,loss_train: 0.6151, loss_test: 0.5686, accuracy: 0.6902356743812561\n",
      "epoch:5, iter:20,loss_train: 0.6694, loss_test: 0.5726, accuracy: 0.7003366947174072\n"
     ]
    }
   ],
   "source": [
    "config = GRUconfig(input_size=train_X.size(-1), hidden_size=512, num_layer=4 ,drop_out_rate=0.2)\n",
    "model = GRU_model(config=config).to(device=device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0004)\n",
    "batch = 32\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accu = []\n",
    "for epoch in range(6):\n",
    "    for i in range(train_X.shape[0] // batch):\n",
    "        optimizer.zero_grad()\n",
    "        out, loss = model.forward(train_X[i * batch:(i + 1) * batch], train_y[i * batch:(i + 1) * batch])\n",
    "        test_out, test_loss = model.forward(test_X, test_y)\n",
    "        test_out = torch.argmax(test_out, dim=1)\n",
    "        correct = (test_out == test_y)\n",
    "        accuracy = correct.float().mean()\n",
    "        test_accu.append(accuracy)\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print(f\"epoch:{epoch}, iter:{i},loss_train: {loss.item():.4f}, loss_test: {test_loss.item():.4f}, accuracy: {accuracy}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'GRU_Layer1')\n",
    "# model_load = GRU_model(config)\n",
    "# model_load.load_state_dict(torch.load('GRU_Layer1', weights_only=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
